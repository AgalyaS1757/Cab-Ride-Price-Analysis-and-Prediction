import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
from scipy import stats
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
import warnings

warnings.filterwarnings('ignore')

# 1. Data Loading and Cleaning
# Make sure to upload the file 'cab_rides_Super_Tool.xlsx' to your Colab session.
try:
    df = pd.read_excel('cab_rides_Super_Tool.xlsx', engine='openpyxl')
except FileNotFoundError:
    try:
        df = pd.read_csv('cab_rides_Super_Tool.xlsx - Sheet1.csv')
    except FileNotFoundError:
        print("Error: File not found.")
        print("Please upload the file 'cab_rides_Super_Tool.xlsx' or 'cab_rides_Super_Tool.xlsx - Sheet1.csv' to your Colab session and try again.")
        exit()

# Drop the first column if it is an unnamed index column
if 'Unnamed: 0' in df.columns:
    df = df.drop(columns=['Unnamed: 0'])

# Convert time_stamp from Unix nanoseconds to a readable datetime format
df['time_stamp_readable'] = pd.to_datetime(df['time_stamp'], unit='ms')

# Clean data: drop rows with missing price values
df.dropna(subset=['price'], inplace=True)

# Remove duplicates if any exist
df.drop_duplicates(inplace=True)

print("--- Data Cleaning and Loading Complete ---")
print(df.info())
print("\n")

# 2. Exploratory Data Analysis and Visualization
print("--- Data Visualization ---")

# Bar chart of average price by cab type
plt.figure(figsize=(8, 5))
sns.barplot(x='cab_type', y='price', data=df)
plt.title('Average Price by Cab Type')
plt.xlabel('Cab Type')
plt.ylabel('Average Price')
plt.show()

# Distribution of prices
plt.figure(figsize=(10, 6))
sns.histplot(df['price'], bins=30, kde=True, color='skyblue')
plt.title('Distribution of Ride Prices')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()

# Price vs. Distance scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x='distance', y='price', data=df, alpha=0.5, color='coral')
plt.title('Price vs. Distance')
plt.xlabel('Distance (miles)')
plt.ylabel('Price ($)')
plt.show()

# 3. Build Predictive Machine Learning Models
print("--- Predictive Analytics Models ---")

# Feature Engineering
# Encode categorical variables for the model
df_model = df.copy()
le = LabelEncoder()
df_model['cab_type_encoded'] = le.fit_transform(df_model['cab_type'])

# Select features and target
features = ['distance', 'surge_multiplier', 'cab_type_encoded']
target = 'price'

X = df_model[features]
y = df_model[target]

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model 1: Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
lr_pred = lr_model.predict(X_test)

print("Linear Regression Model Performance:")
print(f"Mean Absolute Error (MAE): {mean_absolute_error(y_test, lr_pred):.2f}")
print(f"R-squared (R2): {r2_score(y_test, lr_pred):.2f}")
print("\n")

# Model 2: Random Forest Regressor (more advanced)
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

print("Random Forest Regressor Model Performance:")
print(f"Mean Absolute Error (MAE): {mean_absolute_error(y_test, rf_pred):.2f}")
print(f"R-squared (R2): {r2_score(y_test, rf_pred):.2f}")
print("\n")

# 4. A/B Test Simulation and Statistical Analysis
print("--- A/B Test Simulation ---")

# Simulate two hypothetical groups for a new pricing strategy
np.random.seed(42)
# Group A: Control group with a conversion rate of 5%
group_a_conversions = np.random.binomial(n=1000, p=0.05, size=1)[0]
# Group B: Test group with a new strategy, aiming for 6.5%
group_b_conversions = np.random.binomial(n=1000, p=0.065, size=1)[0]

# Perform a two-sample t-test to check for statistical significance
# We use a t-test on the converted/not-converted data
group_a_data = [1] * group_a_conversions + [0] * (1000 - group_a_conversions)
group_b_data = [1] * group_b_conversions + [0] * (1000 - group_b_conversions)

t_stat, p_value = stats.ttest_ind(group_a_data, group_b_data, equal_var=False)

print("Hypothetical A/B Test Results:")
print(f"Group A (Control) Conversions: {group_a_conversions}")
print(f"Group B (Test) Conversions: {group_b_conversions}")
print(f"T-statistic: {t_stat:.4f}")
print(f"P-value: {p_value:.4f}")

# Interpret the result using a significance level (alpha) of 0.05
alpha = 0.05
if p_value < alpha:
    print("Conclusion: The difference between the two groups is statistically significant.")
    print("The new pricing strategy in Group B is likely more effective.")
else:
    print("Conclusion: The difference between the two groups is not statistically significant.")
    print("The observed difference could be due to random chance.")
s